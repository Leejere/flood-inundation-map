---
title: "Estimating Flood Inundation By \"Borrowing\" Experience From Another City"
author: "Jie Li, Yingtong Zhong"
date: "2023-03-28"
output:
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: hide
    theme: journal
    fig_caption: yes
  pdf_document: default
monofont: Hack
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, results = "hide", message = FALSE, warning = FALSE)
```

>Link to video presentation : https://youtu.be/feObLhJLg7o

# Introduction

Flooding is the most common natural disaster for cities near water. With increasing frequency and severity due to factors such as climate change and urbanization, there is growing need for accurate flood inundation maps to help communities prepare and mitigate impacts.

Maps representing flood inundation zones are available in many cities. However, when such a map is not available, it is possible to estimate flood inundation zones by "borrowing" the experience from another city where such maps are available. In such cases, flood inundation (target variable) is assumed to be a function of some other factors (predictors), for which data is more available. By studying the relationships between flood inundation and the predictors in city A, we may be able to predict flood inundation in city B, which lacks a flood inundation map but has data on the predictors.

# Predictors and Workflow

This project is a proof-of-concept for such a methodology. Here, we use data from Calgary, Alberta, Canada, to develop a model that can predict flood inundation zones in Denver, Colorado, USA. The binomial model is used to to deliver the prediction. The following presents the predictors used to predict flood inundation and the associated assumptions

- Elevation (from a digital elevation model): Locations with lower elevation are more likely to be inundated than those with higher elevation.
- Slope (derived from elevation data): Locations with steeper slope are less likely to be inundated.
- Flood accumulation, or the drainage area of each location. Locations with higher flood accumulation are more likely to be inundated.
- Proximity to streams. Locations closer to streams, especially larger streams, are more likely to be inundated. The "streams" here are assumed to be those locations whose drainage area is greater than a certain threshold.
- Impervious zones. Locations whose surface is impervious are more likely to be inundated.

As a proof-of-concept, this project follows the the below workflow:

1. Getting and pre-processing data for both Calgary and Denver.
2. Use a grid system, or "fishnet", of 500-meter cells to cover Calgary and Denver. Use the grid cell as the unit of analysis and calculate the average predictor/target values for each cell. The 500-meter cell size was selected to reach a certain granularity, yet not to strain computing power unnecessarily.
3. For Calgary, use part of the grid cells to build a model predicting flood inundation using the predictors while holding out the other cells.
4. Test the model on the held-out cells and calculate model metrics.
5. Train the model on the entirety of Calgary. Use the model on Denver to predict its flood inundation zone.


```{r libraries, warning = FALSE, message = FALSE}
library(plotROC)
library(tidyverse)
library(sf)
library(ggplot2)
library(spdep)
library(caTools)
library(plotROC)
library(caret)
library(pROC)
library(viridis)
library(gridExtra)
library(cowplot)
library(patchwork)
```

```{r plot-themes, warning = FALSE, echo=TRUE}
plot_theme <- function(
    title_size = 13,
    subtitle_size = 11.5,
    label_size = 10,
    tick_size = 8.5) {
  theme_minimal() +
    theme(
      axis.text.x = element_text(color = "grey60", size = tick_size),
      axis.text.y = element_text(color = "grey60", size = tick_size),
      axis.title.x = element_text(color = "grey20", size = label_size),
      axis.title.y = element_text(color = "grey20", size = label_size),
      plot.title = element_text(color = "gray20", size = title_size, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(color = "gray40", size = subtitle_size, hjust = 0.5),
      axis.line.x = element_line(size = 0.5, colour = "gray10"),
      strip.text = element_text(size = subtitle_size)
    )
}
map_theme <- function(
    title_size = 13,
    subtitle_size = 11.5,
    label_size = 10,
    tick_size = 8.5) {
  plot_theme(title_size, subtitle_size) +
    theme(
      axis.line = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank(),
      axis.title = element_blank(),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      panel.background = element_blank(),
      legend.background = element_blank(),
      legend.title = element_text(size = label_size),
      legend.text = element_text(size = tick_size),
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      panel.border = element_blank(),
      axis.line.x = element_blank(),
      legend.spacing.y = unit(0.6, "cm"),
    )
}
palette_blue_5 <- list("#ffffff", "#c6c7eb", "#8e8fd7", "#5557c3", "#353797")
```

# Data Processing

**Obtaining data**. Calgary's [Open Data Portal](https://data.calgary.ca/) provides data of flood inundation maps for 10-year or 100-year floods. It also provides impervious surface data which also acted as a predictor. The other predictors were all derived from elevation data, accessed through ESRI's "Terrain" dataset in "Living Atlas". For the test city, Denver, the impervious surface data came from the Denver [Open Data Catalog](https://denvergov.org/opendata), and the elevation data was also accessed through ESRI's "Terrain" dataset in "Living Atlas".

**Pre-processing data**. We employed a series of tools in ArcGIS Pro to process elevation data.

1. We calculated the slope (percentage rise) of each cell using the "Slope" tool.
2. Using the "Flow Direction" and "Flow Accumulation" tools, we calculated the drainage area of each cell (presented by the number of cells from which water would flow to the cell of interest).
3. We identified the "streams" as the locations whose drainage areas exceeded certain thresholds. In this case, locations whose drainage areas larger than 50 square kilometers are considered "big streams", and 100 square kilometers "huge streams".
4. We calculated each cell's euclidean distance to the "big streams" and the "huge streams". Note that locations whose drainage areas are smaller than 25 square kilometers are disregarded in our model because we assume that minor streams have little impact in inundation zones.

After this process, we used the "Zonal Statistics As Table" tool to aggregate the predictor and target values into each fishnet. All the data tables are exported and joined together in R. The predictors and target variables are specified below and also in the following code snippet.

-   `dem`: Elevation (meters).
-   `slope`: Slope (percent rise).
-   `dist_big_streams`: Distance (meters) to big streams. Big streams are locations whose drainage areas exceed 50 square kilometers.
-   `dist_huge_streams`: Distance (meters) to huge streams. Huge streams are locations whose drainage areas exceed 100 square kilometers.
-   `flow_accumulation`: Drainage area represented by the number of cells from which water would flow to the cell of interest.
-   `impervious`: Impervious surface as a percentage of area in the cell.
-   `inundation_10pct`: The target variable. Percentage of area that falls inside 10-year flood inundation zones.

```{r features and target variables}
predictors <- c(
  "dem", # --------------- From DEM; meters
  "slope", # ------------- Percentage rise
  "dist_big_streams", # -- Distance (meters) to streams with drainage > 50 km2
  "dist_huge_streams", # - Distance (meters) to streams with drainage > 100 km2
  "flow_accumulation", # - Flow accumulation (number of cells)
  "impervious" # --------- Impervious surface as percentage of area
)

targets <- c(
  "inundation_1pct", # --- Percentage area in 100-year (1%) inundated zone
  "inundation_10pct" # --- Percentage area in 10-year (10%) inundated zone
)
```


```{r add_data, message= FALSE, warning = FALSE}
add_variables_from_csv <- function(
    city_fishnet, # --------A geo-dataframe with fishnet data (empty)
    city_name, # -----------Name of the city (Calgary or Denver)
    variable_list # --------List of variables to add
    ) {
  for (variable in variable_list) {
    path <- paste0(
      "../data/fishnet-output/tbl_", city_name, "_", variable, ".csv"
    )
    data <- read.csv(path) %>%
      rename(id := OID_, !!variable := value)
    city_fishnet <- city_fishnet %>%
      left_join(data, by = "id")
  }

  city_fishnet <- city_fishnet %>%
    # Remove cells that are not within the city boundary
    filter(boundary > 0.9) %>%
    dplyr::select(-boundary)

  return(city_fishnet)
}

calgary <- st_read("../data/fishnet-output/calgary_fishnet.shp") %>%
  dplyr::select(id, geometry) %>%
  add_variables_from_csv("calgary", c(predictors, targets, "boundary"))

denver <- st_read("../data/fishnet-output/denver_fishnet.shp") %>%
  dplyr::select(id, geometry) %>%
  add_variables_from_csv("denver", c(predictors, "boundary"))

```

# Exploratory Analysis

Figure 1 and Figure 2 shows the histogram of the six predictors. As expected, the `dem` predictor generally follows a normal distribution both for Calgary and Denver, whereas the distributions of `flow_accumulation` and `slope` are highly skewed with a long tail. The distribution of `impervious` is largely normal, except for being highly zero-inflated. The distribution of the distance to streams are rather "linear", in that more cells are closer to streams, and a linearly decreasing number of cells fall further away from streams.

```{r plot-hist-calgary, warning = FALSE, message = FALSE, fig.cap = "Figure 1", fig.align = 'center'}
plot_histograms <- function(city_fishnet, predictors, city_name) {
  plot <- city_fishnet %>%
    as.data.frame() %>%
    dplyr::select(predictors) %>%
    dplyr::select_if(is.numeric) %>%
    gather(key = "variable", valu = "value") %>%
    ggplot() +
    geom_histogram(aes(value), fill = palette_blue_5[2]) +
    facet_wrap(~variable, scales = "free", nrow = 2) +
    labs(
      title = paste("Histograms of predictors for", city_name), 
      y = "Number of cells", x = "Value"
    ) +
    plot_theme()
  return(plot)
}
calgary %>%
  plot_histograms(predictors, "Calgary")
```

```{r plot-hist-denver, warning = FALSE, message = FALSE, fig.cap = "Figure 2", fig.align = 'center'}
denver %>% plot_histograms(predictors, "Denver")
```
Figure 3 and Figure 3 shows how these predictors are spacially distributed.

```{r map-predictors-calgary, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 3", fig.width=9}
scale_0to1 <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

calgary_boundary <- st_read("../data/shapefiles/calgary_boundary.shp") %>%
  st_transform(st_crs(calgary))

make_map <- function(city_fishnet, city_boundary, variable_list, legend_name, title, subtitle="") {
  plot <- city_fishnet %>%
    dplyr::select(all_of(variable_list)) %>%
    gather(key = "type", value = "value", -geometry) %>%
    ggplot() +
    geom_sf(aes(fill = value), color = NA) +
    scale_fill_continuous(low = "white", high = palette_blue_5[4], name = legend_name) +
    geom_sf(data = city_boundary, fill = NA, color = palette_blue_5[[2]]) +
    labs(title = title) +
    facet_wrap(~type) +
    map_theme()
  if (subtitle != "") {
    plot = plot + labs(subtitle = subtitle)
  }
  return(plot)
}

calgary %>%
  dplyr::select(all_of(predictors)) %>%
  mutate_at(predictors, scale_0to1) %>% # Scale all predictors to 0-1
  make_map(
    calgary_boundary, 
    predictors, "Value Scaled", 
    "Predictors Mapped, Calgary", 
    "Values scaled between 0 and 1"
  )
```

```{r map-predictors-denver, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 4", fig.width=9}
denver_boundary <- st_read("../data/shapefiles/denver_boundary.shp") %>%
  st_transform(st_crs(denver))
denver %>%
  dplyr::select(all_of(predictors)) %>%
  mutate_at(predictors, scale_0to1) %>% # Scale all predictors to 0-1
  make_map(
    denver_boundary, 
    predictors, "Value Scaled", 
    "Predictors Mapped, Denver", 
    "Values scaled between 0 and 1"
  )
```

Figure 5 shows the percentage of areas by cell inside the 10-year and 100-year flood inundation zones. Note that in our model, the 10-year flood inundation zones are the target for prediction.

```{r map-target, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 5", fig.height = 2.5}

make_map(
  calgary %>% rename(
    "10-year" = inundation_10pct,
    "100-year" = inundation_1pct
  ), calgary_boundary,
  c("10-year", "100-year"),
  "Ratio Inundated",
  "Percentage of Area in Inundation Zones by Cell"
)
```

As we intended to use a binomial model, we needed to set a cutoff value by which the cells would be categorized as "inundated" and "not inundated". In this case, we set this threshold to be 30% - that is, a cell is considered inside the flood inundation zones if over 30% of the area is inside them. Figure 4 shows two bar plots, representing the number of cells inside and outside the 10-year and 100-year flood inundation zones. 

```{r plot-target, warning = FALSE, message=FALSE, fig.width = 6, fig.height = 2.5, fig.align = 'center', fig.cap="Figure 6"}
threshold_flood <- 0.3
calgary <- calgary %>%
  mutate(
    inundated_1pct = ifelse(inundation_1pct > threshold_flood, TRUE, FALSE),
    inundated_10pct = ifelse(inundation_10pct > threshold_flood, TRUE, FALSE)
  )

calgary %>%
  dplyr::select(inundated_1pct, inundated_10pct) %>%
  st_drop_geometry() %>%
  gather(key = "variable", value = "value") %>%
  mutate(variable = ifelse(variable == "inundated_10pct", "10-year", "100-year")) %>%
  ggplot(aes(x = factor(value))) +
  geom_bar(aes(fill = value), position = "dodge", color = palette_blue_5[[4]]) +
  scale_fill_manual(
    values = c("white", palette_blue_5[[4]])
  ) +
  facet_wrap(~variable, scales = "free") +
  labs(
    title = "Number of cells within and outside inundation zones",
    subtitle = "Cells with over 30% inside inundation zones",
    x = "Whether inside inundation zone",
    y = "Number of cells"
  ) +
  plot_theme() +
  theme(legend.position = "none")
```
# Feature Engineering

As the shown in the histograms of Figure 1 and 2, the highly skewed nature of the predictors may not be fit for the binomial model. Therefore, we applied a log-transformation on four predictors: `dist_big_streams`, `dist_huge_streams`, `flow_accumulation`, and `slope`. We also scaled all the variables between 0 and 1 for both cities.

```{r engineer_features, warning = FALSE, message = FALSE}
predictors_used <- c(
  "dem", # --------------- From DEM; meters
  "log_slope", # ------------- Percentage rise
  "log_dist_big_streams",
  "log_dist_huge_streams",
  "log_flow_accumulation",
  "impervious" # --
)
engineer_features <- function(data) {
  data <- data %>%
    mutate(
      log_dist_big_streams = log(dist_big_streams + 1),
      log_dist_huge_streams = log(dist_huge_streams + 1),
      log_flow_accumulation = log(flow_accumulation + 1),
      log_slope = log(slope + 1)
    ) %>%
    mutate_at(predictors_used, scale_0to1)
  return(data)
}
calgary <- calgary %>% engineer_features()
denver <- denver %>% engineer_features()
```

The resulting histograms of the predictors are shown in Figure 7 and 8. After the transformations, the distributions of the predictors became better suited for the binomial model.

```{r plot-engineered-calgary, fig.align = 'center', fig.cap="Figure 7"}

calgary %>% plot_histograms(
  predictors_used, "Calgary"
)
```

```{r plot-engineered-denver, fig.align = 'center', fig.cap="Figure 8"}
denver %>% plot_histograms(
  predictors_used, "Denver"
)
```

Figure 9 and 10 shows the spatial distribution of the engineered and scaled predictors.

```{r map-engineered-calgary, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 9", fig.width = 9}
calgary %>%
  make_map(
    calgary_boundary, predictors_used, "Value Scaled", 
    "Predictors Mapped, Calgary", 
    "Values scaled between 0 and 1"
  )
```

```{r map-engineered-denver, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 10", fig.width=9}
denver %>%
  dplyr::select(all_of(predictors_used)) %>%
  mutate_at(predictors_used, scale_0to1) %>% # Scale all predictors_used to 0-1
  make_map(
    denver_boundary, predictors_used, "Value Scaled", 
    "Predictors Mapped, Denver", 
    "Values scaled between 0 and 1"
  )
```
In the context of spatial analysis, it is important to account for spatial autocorrelation. In this case, flooding is not an individual emergence to each cell. Rather, the likelihood of flooding in one location depends on its nearby locations. Therefore, we also include the spatial lag predictors: that is, the average value of predictors of a cell's queen neighbors.

```{r spatial_lags, warning = FALSE, message = FALSE}
# add predictor spatial lags

calculate_spatial_lags <-
  function(fishnet, predictors, id_col = "id", geometry_col = "geometry") {
    # Create neighbors list using the 'geometry' column
    nb <- poly2nb(fishnet, row.names = fishnet[[id_col]])

    # Create spatial weights matrix
    swm <- nb2listw(nb, style = "W", zero.policy = TRUE)

    # Calculate spatial lags for the specified predictor variables
    for (predictor in predictors) {
      spatial_lag_colname <- paste0("lag_", predictor)
      predictor_values <- as.numeric(fishnet[[predictor]])
      fishnet[[spatial_lag_colname]] <-
        lag.listw(swm, predictor_values, zero.policy = TRUE)
    }

    return(fishnet)
  }

lag_predictors_used <- predictors_used %>%
  sapply(., function(x) {
    paste0("lag_", x)
  }) %>%
  unname()

all_predictors_used <- c(predictors_used, lag_predictors_used)
target_used <- c("inundated_10pct")

calgary_ready <- calgary %>%
  calculate_spatial_lags(predictors_used) %>%
  dplyr::select(all_of(c(all_predictors_used, target_used)), id)

denver_ready <- denver %>%
  calculate_spatial_lags(predictors_used) %>%
  dplyr::select(all_of(all_predictors_used), id)
```

# Building the Model

We built a binomial model using the engineered predictors mentioned above and also the spatially lagged predictors. To test the model, the Calgary dataset was randomly split into training (75%) and testing (25%) sets. 

```{r train-test-split, warning = FALSE, message = FALSE}
train_ratio <- 0.75
sample <- sample.split(calgary_ready$inundated, SplitRatio = train_ratio)
train <- subset(calgary_ready, sample == TRUE)
test <- subset(calgary_ready, sample == FALSE)
```

After building the model on the training set, we used the model to predict the probability of flooding on the test set.

```{r train-model, warning = FALSE, message = FALSE}
train_model <- glm(
  inundated_10pct ~ ., train %>% dplyr::select(-id) %>% st_drop_geometry(),
  family = "binomial"(link = "logit")
)

test$predicted_probs <- predict(train_model, test, type = "response")
```

# Evaluating the Model

The summary output of the training logistic model provides the results of the logistic regression model. The summary shows which features are statistically significant in predicting the target variable in Calgary. In this case, the features `dem`, `slope`, `log_flow_accumulation`, `lag_dem`, `lag_log_dist_big_streams`, `lag_log_dist_huge_streams`, and `lag_impervious` were found to be statistically significant in predicting the target variable. This means that these features have a significant impact on the likelihood of an area being inundated.

```{r model-summary, warning = FALSE, message = FALSE, results = "markup"}
summary(train_model)
```

Figure 12 represents how the prediction performed on the test set. The plot shows two probability density plots of the *predicted* probabilities of inundation. The above is the probability density plot for the *observed* non-inundated cells, whereas the below plot is that for the *observed* inundated cells. 

We can see that for the observed non-inundated cells, the predicted probabilities of flooding concentrated at 0, meaning the model successfully predicted their relative safety. For the observed inundated cells, the predicted probabilities ranged from 0 to 1, meaning the model tended to *underestimate* the risk of inundation for the observed inundated cells. This suggested that we should select a relatively small threshold above which a cell would be considered "inundated".

```{r probability-plot, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 11"}
ggplot(test, aes(x = predicted_probs, fill = as.factor(inundated_10pct))) +
  geom_density() +
  facet_grid(inundated_10pct ~ ., scales = "free") +
  xlim(-0.1, 1) +
  labs(
    x = "Predicted Probability of Inundation",
    y = "Probability Density",
    title = "Distribution of predicted probabilities by observed outcome"
  ) +
  scale_fill_manual(
    values = c(palette_blue_5[[4]], palette_blue_5[[2]]),
    name = "Inundated"
  ) +
  geom_vline(xintercept = .5) +
  plot_theme()
```

Choosing the most suitable "threshold" or cutoff value involves a trade-off: that is, with a lower threshold, more cells would be identified as "inundated", both correctly and incorrectly. Two metrics are used to measure this tradeoff:

-   False Positive Rate (FPR): The ratio of cells *incorrectly identified* as inundated to total *observed* non-inundated cells. One minus FPR is called *specificity*, that is, the ratio of cells *correctly identified* as non-inundated to total *observed* non-inundated cells.
-   True Positive Rate (TPR) (Sensitivity): The ratio of cells *correctly identified* as inundated to total *observed* inundated cells.

The higher the TPR, and the lower the FPR,the better. This means that the model has both a high "**sensitivity**" - ability to spot out the inundated cells, and a high "**specificity**" - ability not to overestimate risks. However, when lowering the cutoff value, both TPR and FPR increases. We should choose a value at which TPR is reasonably high, while FPR has not risen to unacceptable levels.

Figure 11 shows such a trade-off of in the form of an "ROC" curve. The curve shows the model performs very well for the Denver dataset, which is somewhat suspicious and invoke skeptism of over-fitting. This problem will be discussed in the final section.

```{r roc-auc, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 11"}
roc_data <- data.frame(
  D = as.logical(test$inundated_10pct),
  M = test$predicted_probs
)

ggplot(roc_data, aes(d = D, m = M)) +
  geom_roc(color = palette_blue_5[[4]]) +
  geom_abline(slope = 1, intercept = 0, linewidth = 1.5, color = "grey") +
  labs(
    title = "ROC Curve",
    subtitle = paste(
      "Area Under Curve (AUC):",
      round(auc(pROC::roc(test$inundated, test$predicted_probs)), 4)
    ),
    x = "False Positive Rate (FPR)",
    y = "True Positive Rate (TPR)"
  ) +
  plot_theme()
```

In order to choose an optimal threshold, Figure 12 shows the how sensitivity and specificity changes with a changing threshold. As the threshold increases from 0, specificity surged quickly and stays at a high level, whereas sensitivity gradually decreases. Therefore, we should choose a relatively low threshold to optimize both metrics.

```{r sensitivity-specificity, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 12"}
calculate_metrics <- function(data, threshold) {
  prediction <- data$predicted_probs > threshold
  true_positive <- sum(prediction & data$inundated_10pct)
  false_positive <- sum(prediction & !data$inundated_10pct)
  true_negative <- sum(!prediction & !data$inundated_10pct)
  false_negative <- sum(!prediction & data$inundated_10pct)

  sensitivity <- true_positive / (true_positive + false_negative)
  specificity <- true_negative / (true_negative + false_positive)

  return(data.frame(
    threshold = threshold, sensitivity = sensitivity,
    specificity = specificity
  ))
}

thresholds <- seq(0, 0.3, by = 0.001)
metrics <- lapply(thresholds, function(t) calculate_metrics(test, t))
metrics <- do.call(rbind, metrics)

metrics %>%
  gather(key = "metric", value = "value", -threshold) %>%
  ggplot(aes(x = threshold, y = value, color = metric)) +
  geom_line() +
  labs(
    title = "Sensitivity and Specificity by Threshold",
    x = "Threshold",
    y = "Metric"
  ) +
  plot_theme()
```

Figure 13 shows how the model performs when choosing three different cutoff values, where dark purple represents "True Positive", or the correctly identified inundated cells, and white represents "True Negative". Light purple represents "False Positive", or cells that are incorrectly identified as inundated, and the red represents "False Negative", or cells incorrectly identified as non-inundated. 

The red color represents the most danger, as we do not want communities to be unprepared when facing flooding. However, we also do not want communities to be over alarmed by having too much ligh purple.

```{r map-errors, fig.align = 'center', fig.cap="Figure 13"}
draw_predict_outcome <- function(data, threshold, show_legend = FALSE) {
  data$predicted_probs <- predict(
    train_model, data,
    type = "response"
  )

  data <- data %>%
    mutate(
      predicted = ifelse(predicted_probs > threshold, 1, 0),
      outcome = case_when(
        predicted == 1 & inundated_10pct == 1 ~ "True Positive",
        predicted == 1 & inundated_10pct == 0 ~ "False Positive",
        predicted == 0 & inundated_10pct == 1 ~ "False Negative",
        predicted == 0 & inundated_10pct == 0 ~ "True Negative"
      )
    )

  plot <- ggplot(data) +
    geom_sf(aes(fill = outcome), color = NA) +
    labs(
      subtitle = paste0(
        "Prediction Outcome for\n",
        "threshold ",
        threshold
      ),
      fill = "Outcome"
    ) +
    scale_fill_manual(
      values = c(
        "True Positive" = palette_blue_5[[4]],
        "False Positive" = palette_blue_5[[2]],
        "False Negative" = "#c35557",
        "True Negative" = "white"
      ),
      name = "Outcome",
      labels = c(
        "True Positive" = "Risk correctly identified",
        "False Positive" = "Risk overestimated",
        "False Negative" = "Risk underestimated",
        "True Negative" = "No-risk correctly identified"
      )
    ) +
    geom_sf(data = calgary_boundary, color = palette_blue_5[[2]], fill = NA) +
    map_theme()

  if (show_legend == FALSE) {
    plot <- plot + theme(legend.position = "none")
  }

  return(plot)
}
library(ggpubr)
library(cowplot)
plot_01 <- draw_predict_outcome(calgary_ready, 0.02, FALSE)
plot_02 <- draw_predict_outcome(calgary_ready, 0.1, FALSE)
plot_03 <- draw_predict_outcome(calgary_ready, 0.2, FALSE)

shared_legend <- cowplot::get_legend(
  draw_predict_outcome(calgary_ready, 0.1, TRUE)
)
grid.arrange(
  plot_01, plot_02, plot_03, shared_legend,
  ncol = 4, widths = c(1, 1, 1, 1)
)
```

# Predicting Denver

With the model validated, we retrained a model using all the cells of Calgary and used it to predict 10-year flood inundation zones for Denver. Figure 14 shows the predicted probabilities of flood inundation of Denver.

```{r model2, warning = FALSE, message = FALSE}
entire_model <- glm(
  inundated_10pct ~ .,
  calgary_ready %>% dplyr::select(-id) %>% st_drop_geometry(),
  family = "binomial"(link = "logit")
)
```

However, note that the predicted probabilities are *much higher* than those for Calgary. This could be due to the idiosyncrasies of the two cities, rendering the experience of Calgary not being able to be directly borrowed. However, we can still use the probability as a scoring system to rank the risks of flood inundation for different cells.

```{r inundation_denver, warning = FALSE, message = FALSE, fig.align = 'center', fig.cap="Figure 14"}
denver_ready$predicted_probs <- predict(
  entire_model, denver_ready,
  type = "response"
)

ggplot() +
  geom_sf(data = denver_ready, aes(fill = predicted_probs), color = NA) +
  scale_fill_gradient(
    low = "white", high = palette_blue_5[[5]],
    name = "Predicted probability"
  ) +
  geom_sf(data = denver_boundary, color = palette_blue_5[[2]], fill = NA) +
  labs(title = "Predicted Probability of Inundation for Denver") +
  map_theme()
```


# Discussion

This project is a proof-of-concept of the notion that we can estimate the flood inundation zone of one city by "borrowing" the experience from another city, using more widely available data as predictors. As an example, we built of model to predict flood inundation zones in Calgary, AB, Canada and then applied this model to Denver, CO, USA. The predicted probabilities of flooding may be used as a scoring system to rank the risk of flooding in Denver.

However, the predicted probabilities for Denver were much larger than Calgary, indicating the idiosyncrasies of the two cities meant the experience of Calgary may not be directly translated into Denver's practice. To improve on this, the relationship between flood inundation and the predictors should be studied across multiple cities, and the translation of experience should happen among more similar cities.

Another problem was the skepticism of over-fitting, as the model performed exceptionally well for Calgary's test set. We cannot yet claim for sure whether this was over-fitting, as the accuracy of the model has not been tested for Denver. It remains that more cities should be studied in order to create a more generalizable model.